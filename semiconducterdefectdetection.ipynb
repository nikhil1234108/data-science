{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-Xt2Qf-f5ol",
        "outputId": "25ecb18a-2608-4e1f-e5ed-7be54e831f14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "3 images successfully preprocessed.\n",
            "Picture4.jpg: ['Image: Picture4.jpg, Defect: Defect Type 1']\n",
            "Picture2.jpg: ['Image: Picture2.jpg, Defect: Defect Type 1']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-1-1ec12e582813>:69: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
            "  kmeans.fit(dataset)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "!pip install scikit-learn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "def load_and_preprocess_image(dataset_paths, scaler):\n",
        "    \"\"\"Loads and preprocesses a single image.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the image file.\n",
        "        scaler (sklearn.preprocessing.StandardScaler): Scaler used for preprocessing.\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Preprocessed image data.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(dataset_paths, cv2.IMREAD_GRAYSCALE)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (100, 100))\n",
        "        image = image.flatten()\n",
        "        scaler.fit([image])  # Fit the scaler with the image data\n",
        "        image = scaler.transform([image])\n",
        "    return image\n",
        "\n",
        "def load_and_preprocess_dataset(dataset_paths):\n",
        "    \"\"\"Loads and preprocesses a dataset of images.\n",
        "\n",
        "    Args:\n",
        "        dataset_paths (list): List of paths to the image files.\n",
        "        scaler (sklearn.preprocessing.StandardScaler): Scaler used for preprocessing.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: A NumPy array containing preprocessed images.\n",
        "    \"\"\"\n",
        "\n",
        "    dataset_features = []\n",
        "    num_processed_images = 0\n",
        "\n",
        "    scaler = StandardScaler()  # Initialize the scaler\n",
        "\n",
        "    for path in dataset_paths:\n",
        "        image = load_and_preprocess_image(path, scaler)  # Pass the scaler argument\n",
        "        if image is not None:\n",
        "            dataset_features.append(image)\n",
        "            num_processed_images += 1\n",
        "        else:\n",
        "            print(f\"Error: Skipping image {path}\")  # Log specific errors (optional)\n",
        "\n",
        "    print(f\"{num_processed_images} images successfully preprocessed.\")\n",
        "\n",
        "    if len(dataset_features) == 0:\n",
        "        raise ValueError(\"Dataset is empty. Please ensure images are loaded correctly.\")\n",
        "\n",
        "    return np.array(dataset_features)\n",
        "\n",
        "def apply_kmeans(dataset, k):\n",
        "    \"\"\"Trains a KMeans clustering model on the provided dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset (np.ndarray): The preprocessed dataset features.\n",
        "        k (int): The number of clusters to use in KMeans.\n",
        "\n",
        "    Returns:\n",
        "        sklearn.cluster.KMeans: The trained KMeans model.\n",
        "    \"\"\"\n",
        "\n",
        "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "    kmeans.fit(dataset)\n",
        "    return kmeans\n",
        "\n",
        "def detect_defect(dataset_paths, kmeans_model, scaler):\n",
        "    \"\"\"Detects defects in images using the trained KMeans model.\n",
        "\n",
        "    Args:\n",
        "        dataset_paths (list): List of paths to the image files.\n",
        "        kmeans_model (sklearn.cluster.KMeans): The trained KMeans model.\n",
        "        scaler (sklearn.preprocessing.StandardScaler): The scaler used for preprocessing.\n",
        "\n",
        "    Returns:\n",
        "        list: List of defect messages for each image.\n",
        "    \"\"\"\n",
        "\n",
        "    defect_messages = []\n",
        "    if isinstance(dataset_paths, list):\n",
        "        for path in dataset_paths:\n",
        "            message = detect_single_defect(path, kmeans_model, scaler)\n",
        "            defect_messages.append(message)\n",
        "    else:\n",
        "        message = detect_single_defect(dataset_paths, kmeans_model, scaler)\n",
        "        defect_messages.append(message)\n",
        "    return defect_messages\n",
        "\n",
        "def detect_single_defect(dataset_paths, kmeans_model, scaler):\n",
        "    \"\"\"Detects defect in a single image using the trained KMeans model.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the image file.\n",
        "        kmeans_model (sklearn.cluster.KMeans): Trained KMeans model.\n",
        "        scaler (sklearn.preprocessing.StandardScaler): Scaler used for preprocessing.\n",
        "\n",
        "    Returns:\n",
        "        str: Message containing the result of defect detection.\n",
        "    \"\"\"\n",
        "\n",
        "    image = load_and_preprocess_image(dataset_paths, scaler)\n",
        "\n",
        "    if image is not None:\n",
        "        scaled_features = image[0]  # Extract the scaled features from the returned array\n",
        "        scaled_features = scaled_features.reshape((1, -1))\n",
        "        classification = kmeans_model.predict(scaled_features)\n",
        "\n",
        "        labels = ['Defect Type 1', 'Defect Type 2', 'No Defect']\n",
        "\n",
        "        return f\"Image: {dataset_paths}, Defect: {labels[classification[0]]}\"\n",
        "\n",
        "    else:\n",
        "        return f\"Error: Image {dataset_paths} not loaded or is empty\"\n",
        "# Define the paths to your dataset images\n",
        "dataset_paths = ['Picture1.jpg', 'Picture2.jpg', 'Picture3.jpg']  # Update with actual dataset paths\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "dataset = load_and_preprocess_dataset(dataset_paths)\n",
        "dataset = dataset.reshape(-1, 10000)\n",
        "scaler.fit(dataset)\n",
        "\n",
        "# Applying KMeans Clustering on preprocessed dataset\n",
        "kmeans_model = apply_kmeans(dataset, 2)  # Assuming 2 clusters for defective and non-defective\n",
        "\n",
        "# Define the paths to your test images\n",
        "test_image_paths = ['Picture4.jpg','Picture2.jpg']  # Update with actual test image paths\n",
        "\n",
        "# Test the defect detection on each test image\n",
        "for path in test_image_paths:\n",
        "    defect_message = detect_defect(path, kmeans_model, scaler)\n",
        "    print(f\"{path}: {defect_message}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}